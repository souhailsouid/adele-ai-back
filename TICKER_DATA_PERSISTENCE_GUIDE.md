# Guide : Persistance des Donn√©es Ticker dans Supabase

## üìã Vue d'ensemble

Ce syst√®me permet de **persister automatiquement** les donn√©es d'options flow, dark pool et short interest dans Supabase, avec **v√©rification de fra√Æcheur** bas√©e sur la date des donn√©es (pas seulement `expires_at`).

## üéØ Probl√®me r√©solu

**Avant** :
- Les donn√©es √©taient cach√©es dans une table g√©n√©rique `unusual_whales_cache` qui n'existait pas
- Pas de v√©rification de fra√Æcheur bas√©e sur la date r√©elle des donn√©es
- Les donn√©es √©taient perdues entre les invocations Lambda
- Pas de persistance structur√©e pour options flow, dark pool, short interest

**Apr√®s** :
- ‚úÖ Tables d√©di√©es dans Supabase : `options_flow`, `dark_pool_trades`, `short_interest`
- ‚úÖ V√©rification de fra√Æcheur bas√©e sur `data_date` (date r√©elle des donn√©es)
- ‚úÖ Persistance automatique lors de chaque fetch
- ‚úÖ R√©utilisation des donn√©es fra√Æches sans appels API inutiles

## üìä Architecture

### Tables Supabase

#### 1. `unusual_whales_cache` (table g√©n√©rique)
- **Usage** : Cache g√©n√©rique pour toutes les APIs UW utilisant `cache_key`
- **Structure** :
  - `cache_key` (TEXT, UNIQUE) : Cl√© de cache (ex: `"uw_recent_flows_NVDA_{limit:30}"`)
  - `data` (JSONB) : Donn√©es brutes
  - `data_date` (TIMESTAMPTZ) : Date des donn√©es si disponible
  - `cached_at` (TIMESTAMPTZ) : Date de mise en cache
  - `expires_at` (TIMESTAMPTZ) : Date d'expiration

#### 2. `options_flow` (am√©lior√©e)
- **Usage** : Stockage structur√© des donn√©es d'options flow
- **Colonnes ajout√©es** :
  - `data_date` (DATE) : Date de trading (ISO format: YYYY-MM-DD)
  - `call_volume`, `put_volume` : Volumes agr√©g√©s
  - `call_premium`, `put_premium` : Premiums agr√©g√©s
  - `date` : Date de trading (pour compatibilit√©)

#### 3. `dark_pool_trades` (am√©lior√©e)
- **Usage** : Stockage structur√© des trades dark pool
- **Colonnes ajout√©es** :
  - `data_date` (DATE) : Date du trade
  - `executed_at` (TIMESTAMPTZ) : Timestamp d'ex√©cution
  - `institution` (TEXT) : Institution
  - `market_center` (TEXT) : Centre de march√©

#### 4. `short_interest` (nouvelle)
- **Usage** : Stockage des donn√©es de short interest
- **Structure** :
  - `ticker` (TEXT) : Ticker
  - `short_interest` (BIGINT) : Nombre d'actions vendues √† d√©couvert
  - `float` (BIGINT) : Float disponible
  - `short_interest_ratio` (DECIMAL) : Ratio short interest / float
  - `days_to_cover` (DECIMAL) : Jours pour couvrir les shorts
  - `data_date` (DATE) : Date des donn√©es
  - `data` (JSONB) : Donn√©es brutes compl√®tes
  - `cached_at`, `expires_at` : M√©tadonn√©es de cache
  - **Contrainte unique** : `(ticker, data_date)` pour √©viter les doublons

## üîÑ Flux de donn√©es

### Options Flow

```typescript
// 1. V√©rifier la fra√Æcheur dans Supabase
const cached = await supabase
  .from('options_flow')
  .select('*')
  .eq('ticker', 'NVDA')
  .gt('expires_at', NOW())
  .order('data_date', { ascending: false })
  .limit(100);

// 2. Si fra√Æches (< 1h), retourner depuis cache
if (ageHours < 1) {
  return { data: cached, fromCache: true };
}

// 3. Sinon, fetch depuis API UW
const freshData = await uw.getUWRecentFlows('NVDA', { limit: 30 });

// 4. Stocker dans Supabase avec data_date
await supabase
  .from('options_flow')
  .upsert(recordsToInsert);

// 5. Retourner les nouvelles donn√©es
return { data: freshData, fromCache: false };
```

### Dark Pool & Short Interest

M√™me logique, mais avec des `maxAgeHours` diff√©rents :
- **Dark Pool** : 24h (change moins fr√©quemment)
- **Short Interest** : 24h (change quotidiennement)

## üõ†Ô∏è Utilisation

### Dans la route `/ai/ticker-activity-analysis`

```typescript
import { TickerDataPersistenceService } from '../services/ticker-data-persistence.service';

const persistenceService = new TickerDataPersistenceService();

// Options Flow avec persistance
const optionsFlowResult = await persistenceService.getOrFetchOptionsFlow(
  ticker,
  async () => {
    const result = await timeout(uw.getUWRecentFlows(ticker, { limit: 30 }), 5000, 1);
    return result.value?.data || [];
  },
  1 // maxAgeHours: 1h
);

// Dark Pool avec persistance
const darkPoolResult = await persistenceService.getOrFetchDarkPool(
  ticker,
  async () => {
    const result = await timeout(uw.getUWDarkPoolTrades(ticker, { limit: 30 }), 5000, 1);
    return result.value?.data || [];
  },
  24 // maxAgeHours: 24h
);

// Short Interest avec persistance
const shortInterestResult = await persistenceService.getOrFetchShortInterest(
  ticker,
  async () => {
    const result = await timeout(uw.getUWShortInterestAndFloat(ticker), 4000, 1);
    return result.value?.data || null;
  },
  24 // maxAgeHours: 24h
);
```

## üìÖ V√©rification de fra√Æcheur

Le syst√®me utilise **3 niveaux de dates** pour d√©terminer la fra√Æcheur :

1. **`data_date`** (priorit√© 1) : Date r√©elle des donn√©es depuis l'API
2. **`executed_at`** (priorit√© 2) : Timestamp d'ex√©cution (pour dark pool)
3. **`cached_at`** (priorit√© 3) : Date de mise en cache (fallback)

```typescript
const referenceDate = dataDate || executedAt || cachedAt;
const ageHours = (now.getTime() - referenceDate.getTime()) / (1000 * 60 * 60);

if (ageHours < maxAgeHours) {
  // Utiliser les donn√©es en cache
  return { data: cached, fromCache: true };
}
```

## üîß Migration SQL

La migration `008_unusual_whales_cache_and_short_interest.sql` :
1. Cr√©e la table `unusual_whales_cache` (pour le cache g√©n√©rique UW)
2. Cr√©e la table `short_interest` (nouvelle)
3. Am√©liore `options_flow` et `dark_pool_trades` (ajoute `data_date` et colonnes suppl√©mentaires)
4. Configure RLS (Row Level Security) pour permettre l'acc√®s service_role
5. Cr√©e des fonctions utilitaires (`cleanup_expired_uw_cache`, `is_data_fresh`)

## üìà Avantages

1. **Performance** : R√©duction des appels API inutiles (r√©utilisation des donn√©es fra√Æches)
2. **Fiabilit√©** : Donn√©es persist√©es m√™me en cas d'erreur API
3. **Tra√ßabilit√©** : Historique des donn√©es avec dates r√©elles
4. **Co√ªt** : R√©duction des co√ªts API UW (moins d'appels)
5. **Latence** : R√©ponses plus rapides pour les donn√©es en cache

## üöÄ Prochaines √©tapes

1. **Insiders** : Ajouter la persistance pour les donn√©es d'insiders
2. **Institutional Ownership** : Ajouter la persistance pour l'ownership institutionnel
3. **Nettoyage automatique** : Cr√©er un cron job pour nettoyer les donn√©es expir√©es
4. **Analytics** : Ajouter des m√©triques sur l'utilisation du cache (hit rate, etc.)

## üìù Notes

- Les donn√©es sont stock√©es avec un TTL de 24h par d√©faut (`expires_at`)
- La v√©rification de fra√Æcheur utilise `data_date` si disponible, sinon `cached_at`
- Les donn√©es sont upsert√©es (pas de doublons) gr√¢ce aux contraintes uniques
- Le service g√®re gracieusement les erreurs (fallback vers fetch direct si Supabase √©choue)





