# ğŸš€ Guide de Migration: Extreme Budget Architecture

## ğŸ“‹ Vue d'ensemble

Migration complÃ¨te de Supabase vers **S3 + Athena** pour rÃ©duire les coÃ»ts Ã  **$0-5/mois** (vs $25-30/mois Supabase).

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         S3 Data Lake (Parquet)          â”‚
â”‚  s3://bucket/data/{table}/year/month/   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Amazon Athena (Queries)          â”‚
â”‚     $5/TB scanned (pay-per-query)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         Lambda Functions (API)           â”‚
â”‚      Utilise Athena pour requÃªtes       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Ã‰tapes de Migration

### 1. Installer les dÃ©pendances

```bash
npm install @aws-sdk/client-s3 @aws-sdk/client-athena parquetjs
```

### 2. CrÃ©er l'infrastructure Terraform

```bash
cd infra/terraform

# CrÃ©er S3 Data Lake
terraform apply -target=aws_s3_bucket.data_lake

# CrÃ©er Athena
terraform apply -target=aws_athena_database.main
terraform apply -target=aws_athena_workgroup.main
```

### 3. Migrer les donnÃ©es

#### Migrer une table Ã  la fois:

```bash
# Companies (8K rows)
npx tsx scripts/migrate_to_s3_parquet.ts \
  --table=companies \
  --s3-bucket=personamy-prod-data-lake \
  --batch-size=10000

# Fund Holdings (5.7M rows - peut prendre du temps)
npx tsx scripts/migrate_to_s3_parquet.ts \
  --table=fund_holdings \
  --s3-bucket=personamy-prod-data-lake \
  --batch-size=100000

# Company Filings (206K rows)
npx tsx scripts/migrate_to_s3_parquet.ts \
  --table=company_filings \
  --s3-bucket=personamy-prod-data-lake \
  --batch-size=50000

# Fund Holdings Diff
npx tsx scripts/migrate_to_s3_parquet.ts \
  --table=fund_holdings_diff \
  --s3-bucket=personamy-prod-data-lake \
  --batch-size=50000
```

#### Test avec --dry-run:

```bash
npx tsx scripts/migrate_to_s3_parquet.ts \
  --table=companies \
  --s3-bucket=personamy-prod-data-lake \
  --limit=100 \
  --dry-run
```

### 4. CrÃ©er les tables Athena

1. **Se connecter Ã  Athena Console** (AWS Console â†’ Athena)
2. **SÃ©lectionner la database**: `personamy_prod`
3. **ExÃ©cuter les DDL** depuis `infra/athena/ddl/create_tables.sql`
4. **Repartitionner** aprÃ¨s chaque table:
   ```sql
   MSCK REPAIR TABLE companies;
   MSCK REPAIR TABLE fund_holdings;
   ```

### 5. Tester les requÃªtes Athena

```sql
-- Test simple
SELECT COUNT(*) FROM companies;
SELECT COUNT(*) FROM fund_holdings;

-- Test de corrÃ©lation (exemple)
SELECT 
  h1.ticker,
  SUM(h1.market_value) as fund1_value,
  SUM(h2.market_value) as fund2_value
FROM fund_holdings h1
INNER JOIN fund_holdings h2 ON h1.ticker = h2.ticker
WHERE h1.fund_id = 1 AND h2.fund_id = 2
GROUP BY h1.ticker
LIMIT 10;
```

### 6. Migrer le code API

#### Avant (Supabase):
```typescript
const { data } = await supabase
  .from('fund_holdings')
  .select('*')
  .eq('fund_id', fundId);
```

#### AprÃ¨s (Athena):
```typescript
import { executeAthenaQuery } from '@/athena/correlation';

const results = await executeAthenaQuery(`
  SELECT ticker, SUM(market_value) as total_value
  FROM fund_holdings
  WHERE fund_id = ${fundId}
  GROUP BY ticker
  ORDER BY total_value DESC
`);
```

### 7. Exemple: CorrÃ©lation entre investisseurs

```typescript
import { getInvestorCorrelation } from '@/athena/correlation';

// Comparer Scion vs ARK
const correlation = await getInvestorCorrelation(
  'Scion Asset Management',
  'ARK Investment Management'
);

console.log(`Overlap: ${correlation.total_overlap_tickers} tickers`);
console.log(`Total value: $${correlation.total_overlap_value.toLocaleString()}`);
console.log(`Correlation score: ${correlation.correlation_score.toFixed(2)}`);
```

---

## ğŸ’° CoÃ»ts EstimÃ©s

### S3 Storage
- **Standard**: $0.023/GB/mois
- **Standard-IA** (aprÃ¨s 90 jours): $0.0125/GB/mois
- **Glacier** (aprÃ¨s 1 an): $0.004/GB/mois

**Exemple**: 10GB de donnÃ©es
- Mois 1-3: 10GB Ã— $0.023 = $0.23/mois
- Mois 4-12: 10GB Ã— $0.0125 = $0.125/mois
- AprÃ¨s 1 an: 10GB Ã— $0.004 = $0.04/mois

### Athena
- **$5/TB scanned** (pay-per-query)
- **Premier 10TB/mois**: Gratuit (Free Tier)

**Exemple**: 100 requÃªtes/mois, 1GB scannÃ© par requÃªte
- 100 Ã— 1GB = 100GB = 0.1TB
- CoÃ»t: 0.1TB Ã— $5 = $0.50/mois

### Total Mensuel
- **S3**: ~$0.20/mois (10GB)
- **Athena**: ~$0.50/mois (100 requÃªtes)
- **Total**: **~$0.70/mois** (vs $25-30/mois Supabase)

**Ã‰conomie**: **~$24-29/mois** (97% de rÃ©duction)

---

## âš ï¸ Points d'Attention

### 1. Latence Athena
- **PremiÃ¨re requÃªte**: 2-5 secondes (cold start)
- **RequÃªtes suivantes**: 1-3 secondes
- **Solution**: Cache CloudFront pour requÃªtes frÃ©quentes

### 2. Partitionnement
- **Obligatoire** pour performances optimales
- **Structure**: `year=2025/month=12/`
- **Avantage**: Athena scanne uniquement les partitions nÃ©cessaires

### 3. Compression Parquet
- **Snappy**: Bon compromis vitesse/compression
- **RÃ©duction**: ~70% de la taille originale
- **Avantage**: Moins de donnÃ©es scannÃ©es = moins cher

### 4. Limites Athena
- **Query timeout**: 30 minutes max
- **Result size**: 10MB max (utiliser pagination)
- **Concurrent queries**: 20 par dÃ©faut (augmentable)

---

## ğŸ”§ Maintenance

### Ajouter de nouvelles donnÃ©es

```typescript
// AprÃ¨s parsing d'un nouveau filing
import { S3Client, PutObjectCommand } from '@aws-sdk/client-s3';
import { convertToParquet } from '@/utils/parquet';

const parquetBuffer = await convertToParquet(holdings, schema);
await s3Client.send(new PutObjectCommand({
  Bucket: 'personamy-prod-data-lake',
  Key: `data/fund_holdings/year=${year}/month=${month}/data_${filingId}.parquet`,
  Body: parquetBuffer,
}));

// Repartitionner (automatique avec projection, ou manuel)
// MSCK REPAIR TABLE fund_holdings;
```

### Optimiser les coÃ»ts

1. **Partitionnement intelligent**: Utiliser `year/month` pour filtrer efficacement
2. **Compression**: Toujours utiliser Snappy
3. **Lifecycle S3**: Transition vers IA/Glacier aprÃ¨s 90 jours
4. **Cache**: Mettre en cache les requÃªtes frÃ©quentes

---

## ğŸ“š Ressources

- [Athena Documentation](https://docs.aws.amazon.com/athena/)
- [Parquet Format](https://parquet.apache.org/)
- [S3 Pricing](https://aws.amazon.com/s3/pricing/)
- [Athena Pricing](https://aws.amazon.com/athena/pricing/)

---

## âœ… Checklist de Migration

- [ ] Installer dÃ©pendances (`@aws-sdk/client-s3`, `@aws-sdk/client-athena`, `parquetjs`)
- [ ] CrÃ©er infrastructure Terraform (S3, Athena)
- [ ] Migrer `companies` vers S3
- [ ] Migrer `fund_holdings` vers S3
- [ ] Migrer `company_filings` vers S3
- [ ] Migrer `fund_holdings_diff` vers S3
- [ ] CrÃ©er tables Athena (DDL)
- [ ] Tester requÃªtes Athena
- [ ] Migrer code API (remplacer Supabase par Athena)
- [ ] Tester endpoints API
- [ ] Monitorer les coÃ»ts CloudWatch
- [ ] DÃ©sactiver Supabase (aprÃ¨s validation complÃ¨te)

---

## ğŸš¨ Rollback Plan

Si besoin de revenir Ã  Supabase:

1. Les donnÃ©es Supabase sont toujours prÃ©sentes (non supprimÃ©es)
2. Rebasculer les variables d'environnement vers Supabase
3. RedÃ©ployer le code avec Supabase
4. Les donnÃ©es S3 restent disponibles pour migration future
