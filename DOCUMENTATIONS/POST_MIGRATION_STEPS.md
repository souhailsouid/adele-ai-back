# âœ… Ã‰tapes AprÃ¨s la Migration SQL

## ðŸŽ¯ Checklist Post-Migration

### 1. âœ… VÃ©rifier que la Migration a RÃ©ussi

Dans Supabase Dashboard â†’ SQL Editor, exÃ©cutez :

```sql
-- VÃ©rifier que extracted_data existe
SELECT column_name, data_type 
FROM information_schema.columns 
WHERE table_name = 'signals' AND column_name = 'extracted_data';
-- Doit retourner : extracted_data | jsonb

-- VÃ©rifier que les tables existent
SELECT table_name 
FROM information_schema.tables 
WHERE table_schema = 'public' 
AND table_name IN ('alert_keywords', 'alerts_sent');
-- Doit retourner : alert_keywords et alerts_sent

-- VÃ©rifier les triggers
SELECT trigger_name, event_object_table
FROM information_schema.triggers
WHERE event_object_table IN ('signals', 'alert_keywords');
-- Doit retourner : trigger_alert_on_signal_insert et update_alert_keywords_updated_at
```

---

### 2. ðŸ”” Activer Realtime dans le Dashboard

**IMPORTANT** : La migration SQL active Realtime, mais vous devez AUSSI l'activer dans le Dashboard.

1. **Aller dans Supabase Dashboard**
2. **Database** â†’ **Replication**
3. **Trouver la table `signals`**
4. **Cocher "Enable Realtime"** âœ…
5. **Sauvegarder**

**VÃ©rification** :
```sql
SELECT * FROM pg_publication_tables 
WHERE pubname = 'supabase_realtime' AND tablename = 'signals';
-- Doit retourner une ligne
```

---

### 3. ðŸ”’ VÃ©rifier RLS (SÃ©curitÃ©)

```sql
-- VÃ©rifier que RLS est activÃ©
SELECT tablename, rowsecurity 
FROM pg_tables 
WHERE schemaname = 'public' 
AND tablename IN ('signals', 'alert_keywords', 'alerts_sent');
-- Doit retourner rowsecurity = true pour toutes

-- VÃ©rifier les policies
SELECT tablename, policyname, cmd
FROM pg_policies 
WHERE tablename = 'signals';
-- Doit retourner :
-- - "Allow read signals" (SELECT)
-- - "Allow write signals for service_role" (INSERT)
-- - "Allow update signals for service_role" (UPDATE)
-- - "Allow delete signals for service_role" (DELETE)
```

---

### 4. ðŸ§ª Tester avec un Signal

```sql
-- InsÃ©rer un signal de test avec extracted_data
INSERT INTO signals (source, type, raw_data, extracted_data)
VALUES (
  'rss',
  'macro',
  '{"title": "FinancialJuice: Tokyo CPI +2.3% (Forecast +2.5%)", "feed": "financial-juice"}',
  '{"actual": 2.3, "forecast": 2.5, "surprise": "negative", "surpriseMagnitude": 0.2, "indicator": "CPI", "region": "JP"}'
);

-- VÃ©rifier que le signal a Ã©tÃ© crÃ©Ã©
SELECT 
  id,
  raw_data->>'title' as title,
  extracted_data->>'actual' as actual,
  extracted_data->>'forecast' as forecast,
  extracted_data->>'surprise' as surprise
FROM signals
WHERE source = 'rss'
ORDER BY created_at DESC
LIMIT 1;
-- Doit retourner le signal avec extracted_data
```

---

### 5. ðŸ”” Tester le Trigger d'Alerte

```sql
-- InsÃ©rer un signal avec keyword "Trump"
INSERT INTO signals (source, type, raw_data)
VALUES (
  'rss',
  'macro',
  '{"title": "FinancialJuice: Trump announces new policy", "feed": "financial-juice"}'
);

-- VÃ©rifier qu'une alerte a Ã©tÃ© crÃ©Ã©e
SELECT 
  a.*,
  s.raw_data->>'title' as signal_title
FROM alerts_sent a
JOIN signals s ON a.signal_id = s.id
ORDER BY a.sent_at DESC
LIMIT 1;
-- Doit retourner une alerte avec keyword = "Trump" et status = "pending"
```

---

### 6. ðŸš€ Rebuild et RedÃ©ployer Collector-RSS

L'extraction de donnÃ©es est intÃ©grÃ©e dans le collector. Il faut rebuild et redÃ©ployer :

```bash
# Build
cd workers/collector-rss
npm install
npm run bundle

# VÃ©rifier que le fichier existe
ls -lh collector-rss.zip
```

**Puis redÃ©ployer via Terraform** (le collector existe dÃ©jÃ  dans votre infra).

---

### 7. ðŸ“± Frontend : Tester l'API

Le frontend peut maintenant utiliser l'API :

```typescript
// Tester la rÃ©cupÃ©ration des signaux avec extracted_data
const response = await fetch(
  `${API_URL}/signals?source=rss&type=macro&limit=10`,
  {
    headers: {
      'Authorization': `Bearer ${accessToken}`,
    },
  }
);

const signals = await response.json();

// VÃ©rifier qu'un signal a extracted_data
const signalWithData = signals.find(
  (s: Signal) => s.raw_data?.extracted_data?.actual !== undefined
);

console.log('Signal avec donnÃ©es extraites:', signalWithData);
console.log('Actual:', signalWithData?.raw_data?.extracted_data?.actual);
```

---

### 8. ðŸ”” Frontend : Tester Realtime (Optionnel)

```typescript
// Tester Supabase Realtime
import { supabase } from '@/lib/supabase';

const channel = supabase
  .channel('test-signals')
  .on('postgres_changes', {
    event: 'INSERT',
    schema: 'public',
    table: 'signals',
    filter: 'source=eq.rss',
  }, (payload) => {
    console.log('Nouveau signal reÃ§u:', payload.new);
  })
  .subscribe();

// Attendre quelques secondes, puis insÃ©rer un signal de test
// Le frontend devrait recevoir la notification instantanÃ©ment
```

---

## âœ… Checklist Finale

- [ ] Migration SQL exÃ©cutÃ©e sans erreur
- [ ] `extracted_data` existe sur la table `signals`
- [ ] Tables `alert_keywords` et `alerts_sent` crÃ©Ã©es
- [ ] Triggers crÃ©Ã©s (`trigger_alert_on_signal_insert`, `update_alert_keywords_updated_at`)
- [ ] Realtime activÃ© dans Dashboard Supabase
- [ ] Realtime vÃ©rifiÃ© avec `pg_publication_tables`
- [ ] RLS activÃ© et policies crÃ©Ã©es
- [ ] Test : Signal avec `extracted_data` insÃ©rÃ©
- [ ] Test : Alerte crÃ©Ã©e automatiquement (trigger)
- [ ] Collector-RSS rebuild et redÃ©ployÃ©
- [ ] Frontend : Test API `/signals` avec `extracted_data`
- [ ] Frontend : Test Realtime (optionnel)

---

## ðŸ› DÃ©pannage

### Realtime ne fonctionne pas

**VÃ©rifier** :
1. âœ… Migration SQL appliquÃ©e
2. âœ… "Enable Realtime" cochÃ© dans Dashboard
3. âœ… `SELECT * FROM pg_publication_tables` retourne `signals`

**Si toujours pas de Realtime** :
```sql
-- RÃ©activer
ALTER PUBLICATION supabase_realtime DROP TABLE signals;
ALTER PUBLICATION supabase_realtime ADD TABLE signals;
-- Puis re-vÃ©rifier dans Dashboard
```

### Aucune donnÃ©e extraite

**VÃ©rifier** :
1. âœ… Collector-RSS rebuild et redÃ©ployÃ©
2. âœ… Des signaux RSS rÃ©cents existent
3. âœ… Les signaux contiennent des patterns extractibles (CPI, GDP, etc.)

**Test** :
```sql
-- VÃ©rifier les signaux RSS rÃ©cents
SELECT 
  id,
  raw_data->>'title' as title,
  extracted_data
FROM signals
WHERE source = 'rss'
ORDER BY created_at DESC
LIMIT 10;
```

---

## ðŸ“š Documentation

- **SchÃ©ma JSON** : `DOCUMENTATIONS/SCHEMA_EXTRACTED_DATA.md`
- **SÃ©curitÃ© RLS** : `DOCUMENTATIONS/SECURITE_RLS.md`
- **Guide Frontend** : `DOCUMENTATIONS/FRONTEND_GUIDE_DATA_EXTRACTION_ALERTS.md`
- **Realtime** : `DOCUMENTATIONS/REALTIME_CONFIGURATION.md`

---

## ðŸŽ‰ C'est Fait !

Une fois toutes les Ã©tapes complÃ©tÃ©es, le systÃ¨me est opÃ©rationnel :

- âœ… Extraction de donnÃ©es automatique
- âœ… Alertes temps rÃ©el (frontend via Realtime)
- âœ… SÃ©curitÃ© RLS configurÃ©e
- âœ… API prÃªte pour le frontend

**Le frontend peut maintenant commencer Ã  implÃ©menter ! ðŸš€**


