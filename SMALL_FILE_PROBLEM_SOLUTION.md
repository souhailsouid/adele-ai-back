# üì¶ Solution au Small File Problem (S3 Parquet)

## Probl√®me

Si on √©crit un fichier Parquet pour chaque transaction, on cr√©e des **milliers de tout petits fichiers** :
- ‚ùå Performance d√©grad√©e (Athena doit scanner beaucoup de fichiers)
- ‚ùå Co√ªts S3 plus √©lev√©s (plus de requ√™tes LIST)
- ‚ùå Latence de requ√™tes augment√©e

## Solution : Batch Writing

### Strat√©gie impl√©ment√©e

1. **Buffer en m√©moire** : Accumuler les transactions avant d'√©crire
2. **Flush par taille** : √âcrire quand le buffer atteint 50 transactions
3. **Flush par timeout** : √âcrire apr√®s 30 secondes m√™me si pas plein
4. **Flush √† la fin** : √âcrire le buffer restant avant de terminer le handler

### Configuration

```typescript
const BUFFER_SIZE = 50;        // √âcrire par batch de 50 transactions
const BUFFER_TIMEOUT = 30000;  // √âcrire apr√®s 30 secondes
```

### Avantages

- ‚úÖ **Moins de fichiers** : 1 fichier pour 50 transactions au lieu de 50 fichiers
- ‚úÖ **Meilleure performance Athena** : Moins de fichiers √† scanner
- ‚úÖ **Co√ªts r√©duits** : Moins de requ√™tes S3 LIST
- ‚úÖ **Latence r√©duite** : Requ√™tes Athena plus rapides

## Monitoring

### M√©trique cl√© : ApproximateNumberOfMessagesVisible

**Interpr√©tation :**

| Valeur | Signification | Action |
|--------|---------------|--------|
| **0** | ‚úÖ Parfait | Queue vide, syst√®me bien calibr√© |
| **1-50** | ‚úÖ Normal | Traitement en temps r√©el |
| **50-100** | ‚ö†Ô∏è Attention | Parser un peu lent, mais acceptable |
| **> 100** | ‚ùå Probl√®me | Parser trop lent ou rate limiting trop restrictif |

### Alarme CloudWatch

Une alarme est configur√©e pour alerter si `ApproximateNumberOfMessagesVisible > 100`.

**Actions recommand√©es si alarme d√©clench√©e :**
1. V√©rifier les logs du parser (erreurs ?)
2. Augmenter le `BUFFER_SIZE` si n√©cessaire
3. V√©rifier le rate limiting (trop restrictif ?)
4. Augmenter le timeout Lambda si parsing trop long

## Optimisations futures

### 1. Glue Job pour consolidation (optionnel)

Si le probl√®me persiste, cr√©er un Glue Job qui :
- Scanne les petits fichiers Parquet
- Les fusionne en fichiers plus gros (100-500 MB)
- Optimise les partitions

**Co√ªt estim√© :** ~$0.44 par DPU-heure (n√©gligeable si mensuel)

### 2. Lambda de consolidation (plus simple)

Cr√©er une Lambda qui :
- S'ex√©cute quotidiennement
- Scanne les fichiers < 1MB dans une partition
- Les fusionne en fichiers plus gros

**Avantage :** Plus simple que Glue, co√ªt similaire

### 3. √âcriture directe optimis√©e

Modifier `write.ts` pour :
- Accumuler les √©critures par partition
- √âcrire un seul fichier par partition/heure
- Utiliser un cache S3 pour les √©critures en cours

## Configuration actuelle

### Buffer Configuration

```typescript
const BUFFER_SIZE = 50;        // Transactions par batch
const BUFFER_TIMEOUT = 30000;  // Timeout en ms (30s)
```

### Taille de fichier attendue

- **50 transactions** √ó ~500 bytes = **~25 KB par fichier**
- **Acceptable** : Fichiers > 1 MB sont optimaux pour Athena
- **Solution** : Si probl√®me, augmenter `BUFFER_SIZE` √† 200-500

### Partitionnement

Les fichiers sont partitionn√©s par `year/month` :
```
s3://bucket/data/insider_trades/year=2025/month=1/insert_*.parquet
```

**Avantage :** Athena peut scanner uniquement les partitions n√©cessaires

## Recommandations

1. **Monitorer** `ApproximateNumberOfMessagesVisible` quotidiennement
2. **Ajuster** `BUFFER_SIZE` si n√©cessaire (50 ‚Üí 100 ‚Üí 200)
3. **Cr√©er un Glue Job** seulement si le probl√®me persiste apr√®s optimisation
4. **V√©rifier les co√ªts S3** : Si > $10/mois, optimiser davantage

## Dashboard CloudWatch

Un dashboard est cr√©√© automatiquement :
- **Queue Depth** : Messages en attente
- **Lambda Metrics** : Invocations, erreurs, dur√©e
- **Queue Activity** : Messages envoy√©s/re√ßus/supprim√©s

**Acc√®s :**
```
AWS Console ‚Üí CloudWatch ‚Üí Dashboards ‚Üí adel-ai-dev-form4-parser-monitoring
```
